import numpy as np
import optuna
import pandas as pd

import sklearn.ensemble
import sklearn.model_selection
import sklearn.svm
import xgboost as xgb
from sklearn.neighbors import KNeighborsClassifier

import utils
from data import main_u
import sklearn.metrics

"""
OPTUNA trials
-------------
You can try it by uncommenting a classifier (except for XGB which is in another function => change study.optimize(objective) to study.optimize(objectivexgb))
We focused on finding the optimal parameter using the recall metric.
"""

# Benchmark classifiers except for xgb
def objective(trial):
    gb_n_estimators = trial.suggest_int("gb_n_estimators", 10, 30)
    gb_learning_rate = trial.suggest_float("gb_learning_rate", 1e-3, 1e-1, log=True)
    gb_max_depth = trial.suggest_int("gb_max_depth", 3, 12)
    classifier_obj = sklearn.ensemble.GradientBoostingClassifier(
        n_estimators=gb_n_estimators,
        learning_rate=gb_learning_rate,
        max_depth=gb_max_depth
    )

    # k = trial.suggest_int('n_neighbors', 1, 30)
    # metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])
    # p = trial.suggest_int('p', 1, 3) if metric == 'minkowski' else 2
    # leaf_size = trial.suggest_int("leaf_size", 10, 80)
    # classifier_obj = KNeighborsClassifier(
    #     n_neighbors=k, metric=metric, p=p, leaf_size=leaf_size
    # )

    # rf_max_depth = trial.suggest_int("rf_max_depth", 10, 20)
    # rf_n_estimators = trial.suggest_int("rf_n_estimators", 50, 200)
    # classifier_obj = sklearn.ensemble.RandomForestClassifier(
    #     max_depth=rf_max_depth,
    #     n_estimators=rf_n_estimators,
    # )

    recall_scorer = sklearn.metrics.make_scorer(sklearn.metrics.recall_score, average='weighted')
    score = sklearn.model_selection.cross_val_score(classifier_obj, X_train, y_train, cv=5, scoring=recall_scorer).mean()
    return score

# XGB
def objectivexgb(trial):
    param = {
        "verbosity": 0,
        "objective": "multi:softmax",
        "num_class": 30,
        # defines booster, gblinear for linear functions.
        "booster": trial.suggest_categorical("booster", ["gbtree", "gblinear", "dart"]),
        # L2 regularization weight.
        "lambda": trial.suggest_float("lambda", 1e-8, 1.0, log=True),
        # L1 regularization weight.
        "alpha": trial.suggest_float("alpha", 1e-15, 1.0, log=True),
        # sampling ratio for training data.
        "subsample": trial.suggest_float("subsample", 0.1, 1.0),
        # sampling according to each tree.
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.1, 1.0),
    }

    if param["booster"] in ["gbtree", "dart"]:
        # maximum depth of the tree, signifies complexity of the tree.
        param["max_depth"] = trial.suggest_int("max_depth", 1, 50)
        # minimum child weight, larger the term more conservative the tree.
        param["min_child_weight"] = trial.suggest_int("min_child_weight", 2, 20)
        param["eta"] = trial.suggest_float("eta", 1e-8, 1.0, log=True)
        # defines how selective algorithm is.
        param["gamma"] = trial.suggest_float("gamma", 1e-10, 1.0, log=True)
        param["grow_policy"] = trial.suggest_categorical("grow_policy", ["depthwise", "lossguide"])

    if param["booster"] == "dart":
        param["sample_type"] = trial.suggest_categorical("sample_type", ["uniform", "weighted"])
        param["normalize_type"] = trial.suggest_categorical("normalize_type", ["tree", "forest"])
        param["rate_drop"] = trial.suggest_float("rate_drop", 1e-8, 1.0, log=True)
        param["skip_drop"] = trial.suggest_float("skip_drop", 1e-10, 1.0, log=True)

    bst = xgb.train(param, dtrain)
    preds = bst.predict(dvalid)
    pred_labels = np.rint(preds)
    recall = sklearn.metrics.recall_score(y_test, pred_labels, average = "weighted")
    return recall

# AUGMENTED DATASET : if unaugmented we used another dataset (generated by the decoder)
df = pd.DataFrame(pd.read_csv("ds.csv"))
# Split the dataset types to undo the scaling performed on continuous features 
df_disc, df_cont = main_u.df_type_split(df) # discrete and continuous features
_, mainX_cont = main_u.df_type_split(main_u.X) # The scaled continuous features (ignore discrete)
X_inv = utils.inverse_sc_cont(mainX_cont, df_cont) # Undo the scaling : ground truth is the continuous features before scaling
X = df_disc.join(X_inv) # Join the unscaled features with discrete features

# Labels were generated for the synthetic data generated by our UNAUGMENTED DECODER and the original labels (main_u.y)
# To use the unaugmented dataset we only need the original labels
# To clarify: 
# 1/ we trained the AAE on unaugmented dataset -> Performed benchmark classification using the dataset generated by the decoder and the original labels (main_u.y)
# 2/ we generate labels using TabNet for the synthetic data -> we trained the DRL algorithm and generate new synthetic data 
# 3/ we generate labels again for the new synthetic dataset -> augmented dataset = original dataset (after preprocessing) + the new synthetic dataset generated with DRL
# 4/ we trained the AAE on augmented dataset where we use the labels generated in STEP 3 -> performed benchmark classification using the dataset generated by the augmented decoder and the labels generated in STEP 2 + original labels
# => Establish ground truth!

# y_rl = pd.DataFrame(pd.read_csv("/results/labels.csv"))
# y_rl = y_rl[y_rl["attack_cat"] != 2] # 2 is a majority class so we drop it
# y = pd.concat([y_rl, main_u.y], axis=0) # Join all labels

X_train, X_test, y_train, y_test = main_u.vertical_split(X, main_u.y) # Split dataset (slight mismatch because the samples were generated by interpolation)
dtrain = xgb.DMatrix(X_train, label=y_train) # ONLY FOR XGB
dvalid = xgb.DMatrix(X_test, label=y_test) # ONLY FOR XGB

study = optuna.create_study(direction="maximize") # maximize the recall metric
study.optimize(objective, n_trials=50) # 200 for XGB, if the results stagnate or do not improve by much we stop the trials
print(study.best_trial)
print("Number of finished trials: ", len(study.trials))
print("Best trial:")
trial = study.best_trial

print("  Value: {}".format(trial.value))
print("  Params: ")
for key, value in trial.params.items():
    print("    {}: {}".format(key, value))

best_params = study.best_params

"""
RESULTS:

Unaugmented data
[I 2025-03-15 15:33:50,599] Trial 154 finished with value: 0.8613886753779144 and parameters: {'booster': 'dart', 'lambda': 5.0292864803340164e-08, 'alpha': 0.0033512466294373347, 'subsample': 0.7722287536019242, 'colsample_bytree': 0.8788241965652669, 'max_depth': 34, 'min_child_weight': 5, 'eta': 0.05922095844261773, 'gamma': 0.00020027098114354085, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'tree', 'rate_drop': 4.157639697493719e-07, 'skip_drop': 2.4062928977967765e-06}. Best is trial 154 with value: 0.8613886753779144.
[I 2025-03-15 13:13:45,965] Trial 13 finished with value: 0.8545258236670931 and parameters: {'n_neighbors': 9, 'metric': 'manhattan', 'leaf_size': 46}. Best is trial 13 with value: 0.8545258236670931.
[I 2025-03-15 12:55:01,807] Trial 3 finished with value: 0.8641521212250719 and parameters: {'rf_max_depth': 13, 'rf_n_estimators': 132}. Best is trial 3 with value: 0.8641521212250719.
[I 2025-03-15 15:54:31,843] Trial 1 finished with value: 0.861919406379052 and parameters: {'gb_n_estimators': 29, 'gb_learning_rate': 0.016756252304922673, 'gb_max_depth': 11}. Best is trial 1 with value: 0.861919406379052.
 
Augmented data
[I 2025-03-21 19:41:14,001] Trial 7 finished with value: 0.8926437909439843 and parameters: {'booster': 'gbtree', 'lambda': 2.032151944034843e-06, 'alpha': 9.557956416749613e-09, 'subsample': 0.9511833522668717, 'colsample_bytree': 0.5585628355617734, 'max_depth': 39, 'min_child_weight': 2, 'eta': 0.01731596321744635, 'gamma': 0.013622238453642105, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 0.8926437909439843.
[I 2025-03-21 19:58:25,129] Trial 1 finished with value: 0.8918550499038217 and parameters: {'gb_n_estimators': 16, 'gb_learning_rate': 0.02429333140155607, 'gb_max_depth': 10}. Best is trial 1 with value: 0.8918550499038217.
[I 2025-03-21 20:19:48,158] Trial 4 finished with value: 0.8937165118749478 and parameters: {'n_neighbors': 23, 'metric': 'euclidean', 'leaf_size': 22}. Best is trial 4 with value: 0.8937165118749478.
[I 2025-03-21 19:43:48,621] Trial 1 finished with value: 0.8932186787195626 and parameters: {'rf_max_depth': 15, 'rf_n_estimators': 50}. Best is trial 1 with value: 0.8932186787195626.
"""

"""
AE+DQN RESULTS:
Unaugmented data
[I 2025-04-01 21:27:38,856] Trial 12 finished with value: 0.4094444444444444 and parameters: {'n_neighbors': 1, 'metric': 'manhattan', 'leaf_size': 79}. Best is trial 12 with value: 0.4094444444444444.
[I 2025-04-05 15:16:06,629] Trial 1 finished with value: 0.4233986928104575 and parameters: {'gb_n_estimators': 11, 'gb_learning_rate': 0.05226220530564107, 'gb_max_depth': 9}. Best is trial 1 with value: 0.4233986928104575.
[I 2025-04-05 15:27:10,982] Trial 2 finished with value: 0.48276143790849674 and parameters: {'rf_max_depth': 19, 'rf_n_estimators': 115}. Best is trial 2 with value: 0.48276143790849674.
[I 2025-04-05 15:31:41,142] Trial 11 finished with value: 0.43673202614379086 and parameters: {'booster': 'gbtree', 'lambda': 0.004684648918210196, 'alpha': 2.094456175692211e-12, 'subsample': 0.9368131549891758, 'colsample_bytree': 0.46705387197901144, 'max_depth': 42, 'min_child_weight': 2, 'eta': 1.2656838990983072e-08, 'gamma': 1.1145681519755535e-10, 'grow_policy': 'lossguide'}. Best is trial 11 with value: 0.43673202614379086.
"""
